

========================================
FILE: ./scripts/populate_historical_data.py
========================================

import os
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
from dotenv import load_dotenv
from supabase import create_client, Client

# --- Configuration ---
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
if not SUPABASE_URL or not SUPABASE_KEY:
    raise ValueError("Supabase credentials not found in .env file")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Set a historical start date for the very first scrape
INITIAL_SCRAPE_START_DATE = "2020-01-01"

def run_scraper():
    """
    Fetches the list of ETFs from the database and then scrapes and caches
    any new historical data for each one.
    """
    # 1. Get the list of symbols to track directly from our new 'etfs' table
    print("Fetching list of ETFs to track from the database...")
    etfs_response = supabase.table('etfs').select('symbol').execute()
    if not etfs_response.data:
        print("No ETFs found in the database. Please populate the 'etfs' table first.")
        return
    
    symbols_to_track = [item['symbol'] for item in etfs_response.data]
    print(f"Found {len(symbols_to_track)} ETFs to process.")

    for symbol in symbols_to_track:
        print(f"--- Processing: {symbol} ---")
        
        # 2. Find the most recent date we have for this symbol in our database
        response = supabase.table('etf_historical_data') \
            .select('date') \
            .eq('symbol', symbol) \
            .order('date', desc=True) \
            .limit(1) \
            .execute()

        latest_date_in_db = None
        if response.data:
            latest_date_in_db = datetime.strptime(response.data[0]['date'], '%Y-%m-%d').date()
            print(f"Latest data in database: {latest_date_in_db}")
            start_date = latest_date_in_db + timedelta(days=1)
        else:
            print("No existing data found. Starting initial scrape from 2020.")
            start_date = datetime.strptime(INITIAL_SCRAPE_START_DATE, '%Y-%m-%d').date()

        # 3. Scrape new data from Yahoo Finance
        today = datetime.now().date()
        if start_date >= today:
            print(f"Data for {symbol} is already up to date. Skipping scrape.")
            continue

        print(f"Scraping new data for {symbol} from {start_date} to {today}...")
        df = yf.download(symbol, start=start_date, end=today, progress=False, auto_adjust=True)

        if df.empty:
            print(f"No new data found from Yahoo Finance for {symbol}.")
            continue

        # 4. Prepare and insert the new records into Supabase
        records_to_insert = []
        for date, row in df.iterrows():
            record = {
                "symbol": symbol,
                "date": date.strftime('%Y-%m-%d'),
                "close_price": round(float(row['Close']), 2)
            }
            records_to_insert.append(record)

        if records_to_insert:
            print(f"Found {len(records_to_insert)} new records to insert.")
            try:
                # Use upsert to handle any potential conflicts gracefully, though the date logic should prevent them.
                _, count = supabase.table('etf_historical_data').upsert(records_to_insert).execute()
                print(f"Successfully inserted/updated records for {symbol}.")
            except Exception as e:
                print(f"An error occurred during insert for {symbol}: {e}")

    print("\n--- Scraping process complete. ---")

if __name__ == "__main__":
    run_scraper()

----------------------------------------



========================================
FILE: ./app.py
========================================

# backend/app.py

from flask import Flask
from flask_cors import CORS
from dotenv import load_dotenv

# Load .env (SUPABASE_URL, SUPABASE_KEY, ALPHA_VANTAGE_KEY, etc.)
load_dotenv()

from routes.health import health_bp
from routes.recommend import recommend_bp
from routes.onboarding import onboard_bp
from routes.chat import chat_bp
from routes.etfs import etfs_bp

app = Flask(__name__)
CORS(app)

# Existing endpoints
app.register_blueprint(health_bp)
app.register_blueprint(recommend_bp)
app.register_blueprint(onboard_bp)
app.register_blueprint(chat_bp)
app.register_blueprint(etfs_bp)

@app.route("/")
def home():
    return {"message": "Finora backend is running"}

if __name__ == "__main__":
    app.run(debug=True, port=5000)

----------------------------------------



========================================
FILE: ./routes/health.py
========================================

# backend/routes/health.py

from flask import Blueprint, jsonify

health_bp = Blueprint("health", __name__)

@health_bp.route("/health", methods=["GET"])
def health():
    return jsonify(status="ok", service="Finora backend")

----------------------------------------



========================================
FILE: ./routes/onboarding.py
========================================

from flask import Blueprint, request, jsonify
from services.onboarding_service import create_profile, get_profile, delete_profile

onboard_bp = Blueprint("onboard", __name__)

@onboard_bp.route("/onboard", methods=["POST"])
def onboard():
    data = request.get_json() or {}
    
    # These field names now exactly match your Supabase table columns
    required = [
        "name",
        "age",
        "income_range",
        "investment_amount",
        "time_horizon",
        "risk_tolerance",
        "investment_goals",
        "experience",
    ]
    
    missing = [f for f in required if f not in data]
    if missing:
        return jsonify({"error": f"Missing fields: {', '.join(missing)}"}), 400

    # Backend Validation
    try:
        name = str(data["name"])
        age = int(data["age"])
        amount = int(data["investment_amount"])

        if not name.strip():
            return jsonify({"error": "Name cannot be empty."}), 400
        if not 18 <= age <= 100:
            return jsonify({"error": "Age must be between 18 and 100."}), 400
        if amount <= 0:
            return jsonify({"error": "Investment amount must be a positive number."}), 400

    except (ValueError, TypeError):
        return jsonify({"error": "Age and investment amount must be valid numbers."}), 400

    # The payload is now a perfect 1-to-1 match with the database schema
    payload = {
        "name": name,
        "age": age,
        "income_range": data["income_range"],
        "investment_amount": amount,
        "time_horizon": data["time_horizon"],
        "risk_tolerance": data["risk_tolerance"],
        "investment_goals": data["investment_goals"],
        "experience": data["experience"],
    }

    try:
        profile_id = create_profile(payload)
    except Exception as e:
        # This will now give a more specific error if a column is missing
        return jsonify({"error": str(e)}), 500

    return jsonify({"status": "ok", "profile_id": profile_id}), 201


# GET and DELETE routes remain the same
@onboard_bp.route("/onboard/<int:profile_id>", methods=["GET"])
def fetch_onboard(profile_id):
    profile = get_profile(profile_id)
    if not profile:
        return jsonify({"error": "Profile not found"}), 404
    return jsonify(profile)


@onboard_bp.route("/onboard/<int:profile_id>", methods=["DELETE"])
def delete_onboard(profile_id):
    success = delete_profile(profile_id)
    if not success:
        return jsonify({"error": "Profile not found or deletion failed"}), 404
    return jsonify({"status": "deleted", "profile_id": profile_id}), 200

----------------------------------------



========================================
FILE: ./routes/__init__.py
========================================



----------------------------------------



========================================
FILE: ./routes/recommend.py
========================================

# backend/routes/recommend.py

from flask import Blueprint, request, jsonify
from services.recommendation_service import recommend_portfolio

recommend_bp = Blueprint("recommend", __name__)

@recommend_bp.route("/recommend", methods=["POST"])
def recommend():
    data = request.get_json() or {}

    # 1) Parse inputs
    risk = data.get("risk_level", "medium")
    total_amount = float(data.get("investment_amount", 0))

    # 2) Delegate recommendation logic to service
    result = recommend_portfolio(risk, total_amount)

    # 3) Return full recommendation payload as JSON
    return jsonify(result)

----------------------------------------



========================================
FILE: ./routes/chat.py
========================================

# backend/routes/chat.py

from flask import Blueprint, request, jsonify
from services.llm_service import chat_with_model

chat_bp = Blueprint("chat", __name__)

@chat_bp.route("/chat", methods=["POST"])
def chat():
    data = request.get_json() or {}
    user_input = data.get("message")
    if not user_input:
        return jsonify({"error": "Missing 'message' field"}), 400
    try:
        reply = chat_with_model(user_input)
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    return jsonify({"reply": reply})

----------------------------------------



========================================
FILE: ./routes/etfs.py
========================================

from flask import Blueprint, jsonify
from services.market_service import (
    get_etf_metadata_from_db,
    get_live_prices_from_fmp,
    get_historical_data_for_period,
    calculate_ytd_return,
    calculate_historical_return,
    calculate_volatility,
    calculate_sharpe_ratio
)

etfs_bp = Blueprint("etfs", __name__)

@etfs_bp.route("/api/etfs/market-data", methods=["GET"])
def get_top_etf_data():
    try:
        etf_metadata = get_etf_metadata_from_db()
        if not etf_metadata:
            return jsonify({"error": "No ETFs found in database."}), 404
        
        symbols = [etf['symbol'] for etf in etf_metadata]
        live_prices = get_live_prices_from_fmp(symbols)
        
        response_data = []
        for etf in etf_metadata:
            symbol = etf['symbol']
            current_price = live_prices.get(symbol)
            
            # Fetch data for the last year (365 days) and for YTD
            historical_data_1yr = get_historical_data_for_period(symbol, 365)
            historical_data_ytd = get_historical_data_for_period(symbol, 240) # Approx days in year so far

            # Perform calculations
            one_year_return = calculate_historical_return(historical_data_1yr)
            ytd_return = calculate_ytd_return(current_price, historical_data_ytd)
            volatility = calculate_volatility(historical_data_1yr)
            sharpe_ratio = calculate_sharpe_ratio(historical_data_1yr)

            response_data.append({
                'symbol': symbol,
                'name': etf['name'],
                'price': current_price or 0.0,
                'ytd_return': ytd_return,
                'expense_ratio': float(etf['expense_ratio']),
                'one_year_return': one_year_return,
                'volatility': volatility,
                'sharpe_ratio': sharpe_ratio
            })
            
        return jsonify(response_data)

    except Exception as e:
        print(f"An error occurred in the market data endpoint: {e}")
        return jsonify({"error": "An internal server error occurred."}), 500

----------------------------------------



========================================
FILE: ./services/etf_service.py
========================================

from .market_service import get_current_price, fetch_daily_history
from datetime import date

# Static metadata for your top ETFs
ETF_INFO = [
    {"ticker": "VTI", "expense_ratio": 0.03},
    {"ticker": "QQQ", "expense_ratio": 0.20},
    {"ticker": "SPY", "expense_ratio": 0.09},
    {"ticker": "BND", "expense_ratio": 0.035},
]

def get_top_etfs():
    today = date.today()
    start_of_year = date(today.year, 1, 1)
    etfs = []

    for info in ETF_INFO:
        symbol = info["ticker"]
        price = get_current_price(symbol)
        history = fetch_daily_history(symbol, output_size="full")
        # Compute YTD return
        ytd_start_price = history.get(start_of_year, {}).get("close", price)
        ytd_return = (price - ytd_start_price) / ytd_start_price if ytd_start_price else 0

        etfs.append({
            "ticker": symbol,
            "current_price": price,
            "ytd_return": ytd_return,
            "expense_ratio": info["expense_ratio"]
        })

    return etfs


----------------------------------------



========================================
FILE: ./services/__init__.py
========================================



----------------------------------------



========================================
FILE: ./services/llm_service.py
========================================

# backend/services/llm_service.py

import os
from openai import OpenAI
from dotenv import load_dotenv

# Load .env so OPENAI_API_KEY is available
load_dotenv()

# Instantiate a client (picks up OPENAI_API_KEY or you can pass api_key=...)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def _load_system_prompt() -> str:
    return (
        "You are Finora, a helpful and knowledgeable financial advisor. "
        "Respond concisely, clearly, and professionally to user queries "
        "about investments, ETFs, allocation, and risk management."
    )

def chat_with_model(user_message: str) -> str:
    """
    Send a user message to the LLM via the new v1.x interface and return its reply.
    """
    system_prompt = _load_system_prompt()
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user",   "content": user_message}
    ]

    # Use the new chat completion call
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=500
    )

    # Extract and return the assistant’s reply text
    return response.choices[0].message.content.strip()

----------------------------------------



========================================
FILE: ./services/market_service.py
========================================

import os
import requests
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from supabase import create_client, Client
from dotenv import load_dotenv

# --- Configuration ---
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
FMP_API_KEY = os.getenv("FMP_API_KEY")

if not all([SUPABASE_URL, SUPABASE_KEY, FMP_API_KEY]):
    raise ValueError("API keys and Supabase credentials must be set in .env file")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- Service Functions ---

def get_etf_metadata_from_db():
    """Fetches all ETF metadata (symbol, name, expense_ratio) from our db."""
    response = supabase.table('etfs').select('symbol, name, expense_ratio').execute()
    return response.data if response.data else []

def get_live_prices_from_fmp(symbols: list) -> dict:
    """Fetches the current price for a list of symbols from FMP in a single call."""
    if not symbols:
        return {}
    symbol_str = ",".join(symbols)
    url = f"https://financialmodelingprep.com/api/v3/quote-short/{symbol_str}?apikey={FMP_API_KEY}"
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        return {item['symbol']: item['price'] for item in data}
    except requests.exceptions.RequestException as e:
        print(f"Error fetching live prices from FMP: {e}")
        return {}

def get_historical_data_for_period(symbol: str, days: int) -> list:
    """Gets cached historical data for a symbol for a specific past period."""
    start_date = datetime.now().date() - timedelta(days=days)
    
    response = supabase.table('etf_historical_data') \
        .select('date, close_price') \
        .eq('symbol', symbol) \
        .gte('date', start_date.strftime('%Y-%m-%d')) \
        .order('date', asc=True) \
        .execute()
    return response.data if response.data else []

# --- Calculation Functions ---

def calculate_historical_return(historical_data: list) -> float:
    """Calculates the total return over the given historical data period."""
    if len(historical_data) < 2:
        return 0.0
    start_price = float(historical_data[0]['close_price'])
    end_price = float(historical_data[-1]['close_price'])
    if start_price == 0:
        return 0.0
    return round(((end_price - start_price) / start_price) * 100, 2)

def calculate_ytd_return(live_price: float, historical_data: list) -> float:
    """Calculates the Year-to-Date return from a series of historical prices."""
    if not historical_data or live_price is None:
        return 0.0
    start_price = float(historical_data[0]['close_price'])
    if start_price == 0:
        return 0.0
    ytd_return = ((live_price - start_price) / start_price) * 100
    return round(ytd_return, 2)

def calculate_volatility(historical_data: list) -> float:
    """Calculates the annualized volatility (standard deviation of daily returns)."""
    if len(historical_data) < 2:
        return 0.0
    prices = pd.Series([float(p['close_price']) for p in historical_data])
    daily_returns = prices.pct_change().dropna()
    volatility = daily_returns.std() * np.sqrt(252) 
    return round(volatility * 100, 2)

def calculate_sharpe_ratio(historical_data: list, risk_free_rate: float = 0.04) -> float:
    """Calculates the Sharpe Ratio, assuming a risk-free rate (e.g., 4%)."""
    if len(historical_data) < 2:
        return 0.0
    prices = pd.Series([float(p['close_price']) for p in historical_data])
    daily_returns = prices.pct_change().dropna()
    if daily_returns.std() == 0:
        return 0.0
    excess_returns = daily_returns - (risk_free_rate / 252)
    sharpe_ratio = (excess_returns.mean() / excess_returns.std()) * np.sqrt(252)
    return round(sharpe_ratio, 2)

----------------------------------------



========================================
FILE: ./services/recommendation_service.py
========================================

# backend/services/recommendation_service.py

from .market_service import get_current_price


def _get_pct_alloc(risk: str) -> dict:
    """
    Maps a user’s risk level to a simple ETF percentage allocation.
    """
    if risk == "low":
        return {"BND": 70, "VTI": 20, "SHY": 10}
    if risk == "medium":
        return {"VTI": 50, "QQQ": 30, "BND": 20}
    if risk == "high":
        return {"QQQ": 60, "VTI": 30, "SPY": 10}
    # Fallback if no recognized risk
    return {"VTI": 100}


def recommend_portfolio(risk: str, total_amount: float) -> dict:
    """
    Builds a detailed portfolio recommendation based on risk and total investment.

    Returns a dict with:
      - risk_level (str)
      - investment_amount (float)
      - allocation (dict of ticker -> { percentage, dollar_amount, price, shares })
    """
    # 1) Get static percentage allocation
    pct_alloc = _get_pct_alloc(risk)

    # 2) Build detailed allocation
    detailed = {}
    for ticker, pct in pct_alloc.items():
        # Dollar slice for this ticker
        dollar_amt = round(total_amount * (pct / 100), 2)
        # Live price lookup
        price = get_current_price(ticker)
        # Compute share count
        shares = round(dollar_amt / price, 4) if price > 0 else 0

        detailed[ticker] = {
            "percentage": pct,
            "dollar_amount": dollar_amt,
            "price": price,
            "shares": shares
        }

    return {
        "risk_level": risk,
        "investment_amount": total_amount,
        "allocation": detailed
    }

----------------------------------------



========================================
FILE: ./services/onboarding_service.py
========================================

# backend/services/onboarding_service.py

import os
from supabase import create_client
from dotenv import load_dotenv

# Load environment variables for Supabase credentials
load_dotenv()
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# Initialize Supabase client
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)


def create_profile(data: dict) -> int:
    """
    Insert an onboarding profile into Supabase and return the new record's ID.
    """
    result = supabase.table("profiles").insert(data).execute()
    try:
        return result.data[0]["id"]
    except Exception:
        raise Exception(f"Unexpected insert response: {result}")


def get_profile(profile_id: int) -> dict:
    """
    Retrieve a single profile by ID from Supabase.
    Returns the row dict or None if not found.
    """
    result = (
        supabase
        .table("profiles")
        .select("*")
        .eq("id", profile_id)
        .single()
        .execute()
    )
    return result.data if getattr(result, "data", None) else None


def delete_profile(profile_id: int) -> bool:
    """
    Delete a profile by ID from Supabase.
    Returns True if a row was deleted, False otherwise.
    """
    result = (
        supabase
        .table("profiles")
        .delete()
        .eq("id", profile_id)
        .execute()
    )
    return bool(getattr(result, "data", None))

----------------------------------------



========================================
FILE: ./services/av_client.py
========================================

# backend/services/av_client.py

import os
from dotenv import load_dotenv, find_dotenv

# this will walk up from this file and load the first .env it finds
load_dotenv(find_dotenv())

API_KEY  = os.getenv("ALPHA_VANTAGE_KEY")
BASE_URL = "https://www.alphavantage.co/query"

if not API_KEY:
    raise RuntimeError("⚠️  ALPHA_VANTAGE_KEY not found in environment")

----------------------------------------


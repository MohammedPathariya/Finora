The Updated Finora Project Roadmap


âœ… Phase 1: Core Product Foundation & MVP (Completed)
This phase represents all the work you have successfully completed to date. You have built a feature-complete and highly functional application that significantly exceeds the initial MVP goals.

Backend: A robust Flask backend with a clean, service-oriented architecture is complete. It features an intelligent, multi-factor recommendation engine, a sophisticated Monte Carlo simulation for projections, and a highly efficient data pipeline using Supabase as a persistent cache.

Frontend: A polished React (TypeScript) single-page application is fully functional. It includes a custom UI component library built upon accessible Radix UI primitives, a well-designed multi-step onboarding wizard, and a data-rich dashboard that is fully integrated with all backend services.

Current State: The Finora application is a demonstrable success in a local development environment, proving the viability of the core concept and technology stack.









ðŸš€ Phase 2: Foundational Hardening & Architectural Refactoring
Goal: Address critical technical debt and improve the core maintainability of the application before scaling up data or features.

Tasks:

Implement Frontend Routing: Replace the useState-based navigation with React Router for a more scalable and robust user experience.

Externalize Configuration: Remove hardcoded API URLs and manage them with environment variables.

Containerize the Backend: Create a Dockerfile for the Flask application to ensure a consistent and reproducible environment.

âœ… Improve Code Documentation: Add detailed docstrings and comments to explain complex logic, especially in the recommendation engine.

âœ… NEW â€” ETF Universe Management: Create a dedicated script or simple admin process to manage the list of ETFs in the Supabase etfs table. This makes it easy to add, remove, or update the securities the application tracks without manual database edits, preparing for the expansion in Phase 4.










ðŸ“ˆ Phase 3: Testing, Validation, & Automation
Goal: Build a comprehensive, automated testing suite and CI/CD pipeline. This non-negotiable phase ensures that as the application scales in data and complexity, its quality and reliability remain high.

Tasks:

Backend Unit & Integration Testing (pytest): Write tests for all backend services, with a focus on validating financial calculations and edge cases.

Frontend Component & Integration Testing (Jest & RTL): Write tests for the UI library and key user flows like onboarding.

Establish CI/CD Pipeline (GitHub Actions): Create a workflow that automatically runs the entire test suite on every code push, preventing bugs from being merged.










âœ¨ Phase 4: Advanced Features & Data Expansion
Goal: With a stable and tested foundation, confidently build new user-facing features and significantly expand the application's data capabilities.

Tasks:

Advanced Data Visualization: Integrate the HistoricalChart component into the MarketDataPage to provide richer, more immediate visual feedback.

Implement Core User Actions: Build the "Download Plan PDF" and "Schedule a Call" features on the dashboard.

NEW â€” Expand ETF Universe: Increase the number of tracked ETFs from ~100 to 500+. Use the management script from Phase 2 to populate the new securities. Profile the backend to ensure performance remains acceptable during recommendation generation with the larger dataset.

NEW â€” Integrate Real-Time Data:

Select and subscribe to a live market data API (e.g., Finnhub, Polygon.io).

Create a new, lean backend endpoint (e.g., /api/prices/live) that fetches real-time quotes from this new provider.

Update the frontend Dashboard and MarketDataPage to periodically call this endpoint, displaying live price updates and more dynamic "YTD Return" calculations. The cached data will still be used for historical charts and initial page loads.










ðŸŒ Phase 5: Production Deployment & Automation
Goal: Push the fully-featured, tested, and data-rich application to a live, public URL and automate its maintenance.

Tasks:

Deploy Backend & Frontend: Deploy the containerized backend to Render and the frontend to Vercel, configuring all production environment variables.

NEW â€” Automate Historical Data Collection: Set up a Cron Job (e.g., Render Cron Jobs) to run the populate_historical_data.py script automatically on a daily schedule. This ensures your application's historical data stays fresh without any manual intervention.

Finalize Documentation: Write the comprehensive README.md with a link to the live demo, architecture diagrams, and setup instructions.

Basic Monitoring: Set up uptime monitoring for the live application endpoints.











ðŸ”® Future Phases (Post-Launch)
After the core ETF product is successfully launched and automated, you can focus on major product expansions.

Asset Class Expansion:

Individual Stocks: Add a new module to the recommendation engine for selecting individual stocks, using different metrics (e.g., P/E ratio, market cap) than those used for ETFs.

Commodities & Alternatives: Integrate data sources for assets like Gold (GLD), Silver (SLV), and Cryptocurrencies (IBIT). This will require adding new "Alternative" categories to the asset allocation models.

Real Estate: Incorporate Real Estate Investment Trusts (REITs) as a distinct asset class within the stock/ETF framework.

User Accounts & Personalization:

Implement user authentication and persistent profiles.

Allow users to save, name, and compare different investment plans.

Track the actual performance of a user's plan over time.





















Finora 2.0: Roadmap to a Premier AI-Powered Financial Advisor
This plan focuses on three core themes: making the advice Holistic, making the AI Proactive, and making the insights Actionable.

Finora 1.0 is Live
This roadmap begins after you have completed the initial 5-phase plan. Your application is deployed, tested, containerized, and has an automated CI/CD pipeline and data collection script.

ðŸš€ Phase 6: User Persistence & Goal-Based Investing
Goal: Evolve Finora from a single-session calculator into a persistent, multi-goal planning tool that users can return to.

Tasks:

Implement User Authentication: Integrate a full authentication system (e.g., Supabase Auth) to allow users to sign up, log in, and securely save their data.

Persistent User Profiles: Link all onboarding data and generated plans to a user's account in the database. When a user logs in, they should see their existing plan immediately.

Introduce Goal-Based Investing: Upgrade the frontend and backend to allow users to define multiple, distinct financial goals (e.g., "Retirement" in 30 years, "House Down Payment" in 7 years).

Develop Sub-Portfolio Logic: Enhance the recommendation_service to generate a unique, risk-adjusted ETF portfolio for each goal. The retirement portfolio might be aggressive (9/10 risk), while the house fund would be much more conservative (3/10 risk). The dashboard will now show an overview and allow the user to drill down into each goal's specific plan.












âœ¨ Phase 7: The Proactive AI Advisory Engine
Goal: Transform the AI from a reactive Q&A bot into a proactive, intelligent advisor that provides unsolicited, personalized insights.

Tasks:

Build the "AI Financial Health Check": Create a new dashboard feature where a user can input their broader financial picture (savings, debt, monthly expenses). An "AI Analyst" agent will then process this data and provide a holistic report in natural language, identifying strengths and weaknesses (e.g., "Your emergency fund is well-funded, but your savings rate could be higher to meet your retirement goal on time.").

Create a Proactive Insights Engine: Develop a backend service that runs periodically. This service will scan market events or changes in a user's portfolio and generate helpful, non-alarming notifications.

Behavioral Nudges: "Market volatility is high this week. Historically, staying invested during downturns has been a successful strategy. Here's a reminder of why your portfolio is diversified."

Opportunity Alerts: "A new, lower-cost S&P 500 ETF has been released. It is very similar to one in your portfolio but has a lower expense ratio. You might consider looking into it."

Implement AI-Powered Scenario Planning: Create an interactive tool where users can ask "what-if" questions. The frontend will pass these to the backend, which will run new simulations and use an LLM to explain the results:

"What if I increase my monthly investment by $300?"

"Show me the impact of retiring 5 years earlier."












ðŸ“ˆ Phase 8: Deep Analytics & Real-World Integration
Goal: Build unshakeable user trust by grounding your recommendations in deep historical data and connecting the plan to the user's actual financial life.

Tasks:

Build a Portfolio Backtesting Tool: This is a truly impressive feature. Create a service that takes a user's recommended Finora portfolio and simulates its performance against historical data (e.g., for the last 10 years). The results can be benchmarked against the S&P 500 to demonstrate the value of diversification.

Implement Portfolio Drift & Rebalancing Alerts: Create a module that tracks the user's target allocation vs. their actual allocation over time. When the portfolio "drifts" significantly (e.g., stocks grow to be 70% of the portfolio instead of the target 60%), the system will alert the user and explain how to rebalance.

Integrate with Plaid for Live Financial Data: This is the ultimate feature to make the project "worth it." Integrating the Plaid API will allow users to securely connect their real-life bank and brokerage accounts. This enables:

Automated Net Worth Tracking: The dashboard can show a live, holistic view of the user's finances.

Automated Financial Health Check: The AI agent from Phase 7 can now work with real data, providing much more accurate insights.

Real Portfolio Tracking: Instead of just a plan, Finora can now track the actual performance of the user's investments.

By the end of this roadmap, Finora will have evolved from an impressive planner into a premier, AI-powered financial co-pilot. It remains true to your original vision while incorporating the technical depth and complexity of a truly standout graduate-level project.







Commands to get the code dumps according to the frontend or backend folders:



find frontend -type f \( -name "*.js" -o -name "*.jsx" -o -name "*.ts" -o -name "*.tsx" -o -name "*.css" -o -name "*.html" -o -name "*.json" \) \
-not -path "*/node_modules/*" -not -path "*/dist/*" \
-exec sh -c 'echo "\n========================================\nFILE: {}\n========================================\n" >> frontend_dump.txt; cat "{}" >> frontend_dump.txt' \;



find backend -type f \( -name "*.py" -o -name "*.r" -o -name "*.yml" -o -name "*.yaml" -o -name "*.json" -o -name "requirements.txt" -o -name "requirements-dev.txt" \) \
-not -path "*/__pycache__/*" -not -path "*/.venv/*" -not -path "*/output/*" \
-exec sh -c 'echo "\n========================================\nFILE: {}\n========================================\n" >> backend_dump.txt; cat "{}" >> backend_dump.txt' \;

